{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:53.871192Z",
     "start_time": "2026-02-08T20:51:50.802193Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD, RMSprop"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:53.886193Z",
     "start_time": "2026-02-08T20:51:53.879194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_model():\n",
    "    model = nn.Sequential(\n",
    "        # Block 1\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        #Block 2\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # Block 3\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(128 * 4 * 4, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, 100)\n",
    "    )\n",
    "    return model"
   ],
   "id": "b5eb114e9eee34f7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:53.901195Z",
     "start_time": "2026-02-08T20:51:53.895196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ],
   "id": "b2b474a9875aa9b9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:55.039193Z",
     "start_time": "2026-02-08T20:51:54.121195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "\n",
    "train_set = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.CIFAR100(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "classes = train_set.classes"
   ],
   "id": "d147a04351daabf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:55.070193Z",
     "start_time": "2026-02-08T20:51:55.057194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = running_loss/len(loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, device, epochs):\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            train_bar.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | TrainLoss: {train_loss:.4f} | ValLoss: {val_loss:.4f} | TrainAcc: {train_acc:.4f}% | ValAcc: {val_acc:.4f}%\")\n",
    "    return history"
   ],
   "id": "d1cec11f5040555b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:55.101193Z",
     "start_time": "2026-02-08T20:51:55.088193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_training_curves(results_dict):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2,2,1)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"train_loss\"], label=f\"{name} Train Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"val_loss\"], label=f\"{name} Val Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"train_acc\"], label=f\"{name} Train Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"val_acc\"], label=f\"{name} Val Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "af5c5085f08bdbab",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T20:51:55.148192Z",
     "start_time": "2026-02-08T20:51:55.119192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_predictions(model, loader, device, n=8):\n",
    "    model.eval()\n",
    "\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    # Move images to SAME device as model\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Move back to CPU for plotting\n",
    "    images = images.cpu().numpy()\n",
    "    labels = labels.cpu()\n",
    "    predicted = predicted.cpu()\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        img = images[i].transpose((1, 2, 0))\n",
    "        img = img * 0.2675 + 0.5071\n",
    "        img = np.clip(img, 0, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"P: {classes[predicted[i]]}\\nT: {classes[labels[i]]}\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "988e5693c3885c41",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-02-08T20:51:55.166193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# 1\n",
    "lrs = [1e-2, 1e-3, 1e-4]\n",
    "results_lr = {}\n",
    "for lr in lrs:\n",
    "    print(f\"\\nTraining with LR={lr}\")\n",
    "    set_seed(0)\n",
    "    model = make_model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train(model, train_loader, test_loader, criterion, optimizer, device, epochs=5)\n",
    "    results_lr[f\"LR={lr}\"] = history\n",
    "plot_training_curves(results_lr)\n",
    "\n",
    "best_lr_model = make_model().to(device)\n",
    "optimizer = optim.Adam(best_lr_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = train(best_lr_model, train_loader, test_loader, criterion, optimizer, device, epochs=5)\n",
    "show_predictions(best_lr_model, test_loader, device)\n",
    "\n",
    "# 2\n",
    "optimizers = [Adam, SGD, RMSprop]\n",
    "results_optimizer = {}\n",
    "for opt_cls in optimizers:\n",
    "    name = opt_cls.__name__\n",
    "    print(f\"\\nTraining with Optimizer: {name}\")\n",
    "    set_seed(0)\n",
    "    model = make_model().to(device)\n",
    "    optimizer = opt_cls(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train(model, train_loader, test_loader, criterion, optimizer, device, epochs=5)\n",
    "    results_optimizer[name] = history\n",
    "plot_training_curves(results_optimizer)\n",
    "\n",
    "# 3\n",
    "losses = {\n",
    "    \"CrossEntropy\": nn.CrossEntropyLoss(),\n",
    "    \"LabelSmoothing0.1\": nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "}\n",
    "\n",
    "results_loss = {}\n",
    "for name, loss in losses.items():\n",
    "    print(f\"\\nTraining with Loss: {name}\")\n",
    "    set_seed(0)\n",
    "    model = make_model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    history = train(model, train_loader, test_loader, loss, optimizer, device, epochs=5)\n",
    "    results_loss[name] = history\n",
    "plot_training_curves(results_loss)"
   ],
   "id": "96cc02b7b4f64f59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "Training with LR=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | TrainLoss: 4.6567 | ValLoss: 4.6074 | TrainAcc: 0.9880% | ValAcc: 1.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | TrainLoss: 4.6093 | ValLoss: 4.6071 | TrainAcc: 0.9340% | ValAcc: 1.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | TrainLoss: 4.6091 | ValLoss: 4.6068 | TrainAcc: 0.8920% | ValAcc: 1.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | TrainLoss: 4.6089 | ValLoss: 4.6078 | TrainAcc: 0.9420% | ValAcc: 1.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | TrainLoss: 4.6091 | ValLoss: 4.6075 | TrainAcc: 0.9660% | ValAcc: 1.0000%\n",
      "\n",
      "Training with LR=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | TrainLoss: 4.0238 | ValLoss: 3.4460 | TrainAcc: 7.7760% | ValAcc: 18.4000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | TrainLoss: 3.5778 | ValLoss: 3.1260 | TrainAcc: 13.4640% | ValAcc: 24.2600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | TrainLoss: 3.3628 | ValLoss: 2.9051 | TrainAcc: 16.6460% | ValAcc: 27.7500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | TrainLoss: 3.2436 | ValLoss: 2.8291 | TrainAcc: 18.3960% | ValAcc: 28.8800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | TrainLoss: 3.1509 | ValLoss: 2.6643 | TrainAcc: 19.7040% | ValAcc: 32.6100%\n",
      "\n",
      "Training with LR=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | TrainLoss: 4.1362 | ValLoss: 3.5721 | TrainAcc: 7.9680% | ValAcc: 19.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | TrainLoss: 3.5500 | ValLoss: 3.1294 | TrainAcc: 16.3940% | ValAcc: 26.4600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | TrainLoss: 3.2088 | ValLoss: 2.8689 | TrainAcc: 22.1040% | ValAcc: 30.6900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | TrainLoss: 2.9837 | ValLoss: 2.6794 | TrainAcc: 26.0160% | ValAcc: 33.8700%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "14587581a172fcdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ac2b065649e1bcc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3e01b82423f9cb82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import SBDataset\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "28367b37867e3907",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SBDSegmentationDataset(Dataset):\n",
    "    def __init__(self, base_dataset, img_transform=None, mask_transform=None):\n",
    "        self.base = base_dataset\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]\n",
    "\n",
    "        if self.img_transform:\n",
    "            img = self.img_transform(img)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return img, mask"
   ],
   "id": "37520ac1bdf092c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256),\n",
    "    interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "train_base = SBDataset(\n",
    "    root='./data',\n",
    "    image_set='train',\n",
    "    mode='segmentation',\n",
    "    download=False\n",
    ")\n",
    "\n",
    "val_base = SBDataset(\n",
    "    root='./data',\n",
    "    image_set='val',\n",
    "    mode='segmentation',\n",
    "    download=False\n",
    ")\n",
    "\n",
    "train_dataset = SBDSegmentationDataset(train_base, img_transform, mask_transform)\n",
    "val_dataset = SBDSegmentationDataset(val_base, img_transform, mask_transform)\n",
    "\n",
    "train_subset = Subset(train_dataset, range(4000))\n",
    "\n",
    "dataset_size = len(train_subset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_subset, [train_size, val_size], generator=torch.Generator().manual_seed(42))"
   ],
   "id": "2d41c2018e90ae0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")"
   ],
   "id": "7af99d04f7c7f270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = DoubleConv(3, 64)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "\n",
    "        return self.out(d1)"
   ],
   "id": "c3c5feac2662f11f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dice_loss_no_bg(pred, target, smooth=1e-6):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "    valid = target != 255\n",
    "    target = target.clone()\n",
    "    target[~valid] = 0\n",
    "\n",
    "    target_oh = nn.functional.one_hot(\n",
    "        target, num_classes=pred.shape[1]\n",
    "    ).permute(0,3,1,2).float()\n",
    "\n",
    "    pred_fg = pred[:, 1:, :, :] * valid.unsqueeze(1)\n",
    "    target_fg = target_oh[:, 1:, :, :] * valid.unsqueeze(1)\n",
    "\n",
    "    intersection = (pred_fg * target_fg).sum(dim=(2,3))\n",
    "    union = pred_fg.sum(dim=(2,3)) + target_fg.sum(dim=(2,3))\n",
    "\n",
    "    dice = (2 * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice.mean()\n"
   ],
   "id": "4976d385a6e0ffd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def iou(preds, target, num_classes=21, ignore_index=255, smooth=1e-6):\n",
    "    preds = preds.argmax(dim=1)\n",
    "    ious = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (target == cls)\n",
    "        valid = target != ignore_index\n",
    "\n",
    "        intersection = ((pred_inds & target_inds) & valid).sum().float().cpu().item()\n",
    "        union = ((pred_inds | target_inds) & valid).sum().float().cpu().item()\n",
    "\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append((intersection + smooth) / (union + smooth))\n",
    "\n",
    "    ious = [iou for iou in ious if not np.isnan(iou)]\n",
    "    return sum(ious) / len(ious)"
   ],
   "id": "35d7c4876c5a2b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    iou_sum = 0\n",
    "    batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.squeeze(1).long().to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            # accuracy\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            valid = masks != 255\n",
    "            correct += (preds[valid] == masks[valid]).sum().item()\n",
    "            total += valid.sum().item()\n",
    "\n",
    "            # IoU\n",
    "            iou_sum += iou(outputs, masks, num_classes=num_classes)\n",
    "            batches += 1\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "    return loss_sum / len(loader), 100 * correct / total, iou_sum / batches"
   ],
   "id": "2926032205f9eafd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, epochs, optimizer, criterion):\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"iou\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_sum, correct, total = 0, 0, 0\n",
    "\n",
    "        for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.squeeze(1).long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, masks) + dice_loss_no_bg(outputs, masks).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            valid = masks != 255\n",
    "\n",
    "            correct += (preds[valid] == masks[valid]).sum().item()\n",
    "            total += valid.sum().item()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        train_loss = loss_sum / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        val_loss, val_acc, val_iou = validate(model, val_loader, criterion)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"iou\"].append(val_iou)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"TrainLoss: {train_loss:.4f} | \"\n",
    "            f\"ValLoss: {val_loss:.4f} | \"\n",
    "            f\"TrainAcc: {train_acc:.2f}% | \"\n",
    "            f\"ValAcc: {val_acc:.2f}% | \"\n",
    "            f\"ValIoU: {val_iou:.4f}\"\n",
    "        )\n",
    "\n",
    "    return history"
   ],
   "id": "5dfec9a895847c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_training_curves(results):\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Training Loss\n",
    "    plt.subplot(2, 3, 1)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"train_loss\"], label=f\"{name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Validation Loss\n",
    "    plt.subplot(2, 3, 2)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"val_loss\"], label=f\"{name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Training Accuracy\n",
    "    plt.subplot(2, 3, 3)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"train_acc\"], label=f\"{name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Validation Accuracy\n",
    "    plt.subplot(2, 3, 4)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"val_acc\"], label=f\"{name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Validation IoU\n",
    "    plt.subplot(2, 3, 5)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"iou\"], label=f\"{name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.title(\"Validation IoU\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "3bb48a1b6ceea5e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = 21\n",
    "\n",
    "results = {}\n",
    "\n",
    "for epoch in [3, 5, 10]:\n",
    "    print(f\"Training with epochs={epoch}\")\n",
    "    model = UNet(num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    class_weights = torch.ones(num_classes)\n",
    "    class_weights[0] = 0.01\n",
    "    class_weights = class_weights.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255, weight=class_weights)\n",
    "    results[f\"epochs={epoch}\"] = train_model(\n",
    "        model, epoch, optimizer, criterion\n",
    "    )"
   ],
   "id": "42adc5858ea2e144",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_training_curves(results)",
   "id": "b74747e52733599e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = 21\n",
    "epochs = 5\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lr in [1e-4, 1e-3, 1e-2]:\n",
    "    print(f\"\\nTraining with LR = {lr}\")\n",
    "\n",
    "    model = UNet(num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    class_weights = torch.ones(num_classes)\n",
    "    class_weights[0] = 0.01\n",
    "    class_weights = class_weights.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        ignore_index=255,\n",
    "        weight=class_weights\n",
    "    )\n",
    "\n",
    "    history = train_model(model, epochs, optimizer, criterion)\n",
    "    results[f\"lr={lr}\"] = history"
   ],
   "id": "923725c9c194b0d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_training_curves(results)",
   "id": "7d42816a72c53438",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_predictions(model, loader, device, n=3):\n",
    "    model.eval()\n",
    "\n",
    "    images, masks = next(iter(loader))\n",
    "    images = images.to(device)\n",
    "    masks = masks.squeeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "    images = images.cpu()\n",
    "    masks = masks.cpu()\n",
    "    preds = preds.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 3*n))\n",
    "\n",
    "    for i in range(n):\n",
    "        # Input image\n",
    "        plt.subplot(n, 3, 3*i + 1)\n",
    "        img = images[i].permute(1, 2, 0)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Ground truth\n",
    "        plt.subplot(n, 3, 3*i + 2)\n",
    "        plt.imshow(masks[i], cmap=\"tab20\")\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Prediction\n",
    "        plt.subplot(n, 3, 3*i + 3)\n",
    "        plt.imshow(preds[i], cmap=\"tab20\")\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "2e29d398fb6631e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = UNet(num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=255,\n",
    "    weight=class_weights\n",
    ")\n",
    "\n",
    "history = train_model(\n",
    "    best_model,\n",
    "    epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion\n",
    ")\n",
    "\n",
    "show_predictions(best_model, val_loader, device, n=3)"
   ],
   "id": "231edf880489a8b5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import OxfordIIITPet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ],
   "id": "607d4d5c19cbf99b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split=\"trainval\"):\n",
    "        self.dataset = OxfordIIITPet(\n",
    "            root=root,\n",
    "            split=split,\n",
    "            target_types=\"segmentation\",\n",
    "            download=True\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.dataset[idx]\n",
    "        img = F.to_tensor(img)\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        binary_mask = mask == 1\n",
    "\n",
    "        if binary_mask.sum() == 0:\n",
    "            return self[(idx+1) % len(self)]\n",
    "\n",
    "        binary_mask = torch.as_tensor(binary_mask, dtype=torch.float32)\n",
    "\n",
    "        pos = torch.where(binary_mask)\n",
    "        xmin = torch.min(pos[1])\n",
    "        xmax = torch.max(pos[1])\n",
    "        ymin = torch.min(pos[0])\n",
    "        ymax = torch.max(pos[0])\n",
    "\n",
    "        boxes = torch.tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32)\n",
    "        labels = torch.ones((1,), dtype=torch.int64)\n",
    "        masks = binary_mask.unsqueeze(0).float()  # float tensor\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks\n",
    "        }\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ],
   "id": "2de81a05b1a06a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "train_dataset = PetDataset(\"./data\", split=\"trainval\")\n",
    "val_dataset = PetDataset(\"./data\", split=\"test\")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_dataset = Subset(train_dataset, range(150))\n",
    "val_dataset = Subset(val_dataset, range(50))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=0, pin_memory=True, persistent_workers=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "9bc9b2b49ed2c40e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, optimizer, device, epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "\n",
    "    for images, targets in pbar:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return running_loss / len(loader)"
   ],
   "id": "4896ecd11c323d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"map\": []\n",
    "        }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, device, epoch, epochs\n",
    "        )\n",
    "\n",
    "        model.train()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss for loss in loss_dict.values())\n",
    "                val_loss += loss\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        map_results = evaluate_map(model, val_loader, device)\n",
    "        map = map_results['map'].item()\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss.item())\n",
    "        history[\"map\"].append(map)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | \"\n",
    "            f\"Map: {map:.4f}\"\n",
    "        )\n",
    "\n",
    "    return history"
   ],
   "id": "6e92c54270087f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_curves(results):\n",
    "    plt.figure(figsize=(15,4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"train_loss\"], label=f\"{name} Train Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"val_loss\"], label=f\"{name} Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for name, history in results.items():\n",
    "        plt.plot(history[\"map\"], label=f\"{name} Map\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Map\")\n",
    "    plt.title(\"Map\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "834ee2872333f627",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_detection(model, dataset, device, n=6, score_thr=0.5):\n",
    "\n",
    "    import random\n",
    "    model.eval()\n",
    "\n",
    "    idxs = random.sample(range(len(dataset)), n)\n",
    "\n",
    "    plt.figure(figsize=(4*n, 4))\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, target = dataset[idx]\n",
    "        with torch.no_grad():\n",
    "            pred = model([img.to(device)])[0]\n",
    "\n",
    "        img_np = img.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(img_np)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        for box in target[\"boxes\"]:\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                                     linewidth=2, edgecolor='g', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        for box, score in zip(pred[\"boxes\"], pred[\"scores\"]):\n",
    "            if score < score_thr:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = box.cpu()\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.set_title(f\"GT=Green\\nPred=Red\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "28e2c5968e9f9d75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "def create_model(num_classes, device):\n",
    "    model = maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "        in_features, num_classes\n",
    "    )\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask, hidden_layer, num_classes\n",
    "    )\n",
    "\n",
    "    return model.to(device)"
   ],
   "id": "4740f471bdbef1e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def evaluate_map(model, loader, device):\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            preds = model(images)\n",
    "\n",
    "            preds = [{k: v.cpu() for k, v in p.items()} for p in preds]\n",
    "            targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "\n",
    "            metric.update(preds, targets)\n",
    "\n",
    "    return metric.compute()"
   ],
   "id": "1d8ec3eaba251f40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "results = {}\n",
    "lr = 1e-3\n",
    "\n",
    "for epochs in [5, 10, 15]:\n",
    "\n",
    "    print(f\"Training with epochs={epochs}\")\n",
    "\n",
    "    model = create_model(num_classes=2, device=device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    history = train_model(model, train_loader, val_loader, optimizer, device, epochs)\n",
    "    map_results = evaluate_map(model, val_loader, device)\n",
    "\n",
    "    results[f\"epochs={epochs}\"] = history\n",
    "\n",
    "plot_curves(results)\n",
    "show_detection(model, val_dataset, device, n=6, score_thr=0.5)"
   ],
   "id": "4800265e0843f82f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = {}\n",
    "\n",
    "lrs = [1e-4, 5e-4, 1e-3]\n",
    "\n",
    "for lr in lrs:\n",
    "    print(f\"Training with lr={lr}\")\n",
    "    model = create_model(num_classes=2, device=device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    history = train_model(model, train_loader, val_loader, optimizer, device, epochs=10)\n",
    "\n",
    "    results[f\"lr={lr}\"] = history\n",
    "\n",
    "plot_curves(results)\n",
    "show_detection(model, val_dataset, device, n=6, score_thr=0.5)"
   ],
   "id": "3ed8af1477435f9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
